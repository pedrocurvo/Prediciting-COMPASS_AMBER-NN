%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a template file
%
% Copy it to a new file with a new name and use it as the basis
% for your article
%
%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[EPJ,twocolumn]{webofc}
\usepackage[varg]{txfonts}   
\usepackage{float}
\usepackage{fancyhdr}

\setlength\headheight{26pt}

\lhead{\includegraphics[width=1.5cm]{LIP.png}}

%PAGE NUMBER (should appear after the first page)
\rhead{\thepage}

% Add here some packages that may be required 
\usepackage{hyperref}
\usepackage{caption}

% Add here some personal commands if needed
\newcommand{\bbar}{\ensuremath{\text{b}\overline{\text}}}

% This specifies the reference of each report
% this will be further specified later on 
\wocname {\texttt{LIP-STUDENTS-23-00}}
\woctitle{\texttt{LIP-STUDENTS-23-00}}

\title{Predicting COMPASS/AMBER Acceptance Using Neural Networks}

\author{Pedro M. P. Curvo\inst{1} \fnsep\thanks{\email{pedro.curvo@tecnico.ulisboa.pt}}}

\institute{
Instituto Superior T\'ecnico, Lisboa, Portugal
\vskip 2mm
{\normalfont\normalsize\textsf Project supervisor: Marcin Stolarski}
\mbox{}\hfill\today\hspace*{16mm}
}

\abstract{The COMPASS experiment, conducted at CERN (the European Organization for Nuclear Research),
    is a global effort to explore the subatomic world, delving into the intricate structure and properties of hadrons.
    This paper focuses on the prediction of particle's acceptance by a Neural Network, since the GEANT4 simulation
    is very time consuming. The data used for the analysis was generated using a LEPTO generator and the full
    simulation of the COMPASS spectrometer was done using the GEANT4 programme. 
    The neural network architecture and training process involved two models with different depths and activations.
    Chi-squared tests are used to evaluate model performance. While accuracy and loss metrics are monitored during
    training, chi-squared values are the key evaluation criteria. Multiple training iterations are conducted to
    account for chi-squared instability, with the best models selected post-training.
    Furthermore, the models are evaluated on a separate dataset to gauge their generalization capabilities.
    We also explore the possibility of reconstructing the spectrometer's structure using muon and hadron angles.
    Despite the challenges presented by this complex problem, the models show promise in predicting the acceptance
    of COMPASS/AMBER. Future work could explore alternative neural network architectures to further improve the
    models.
    The code is hosted at \hyperlink{https://github.com/pedrocurvo/Prediciting-COMPASS_AMBER-NN}{https://github.com/pedrocurvo/Prediciting-COMPASS\_AMBER-NN}


% Keywords: avoid repeating title
\vskip 2mm
{\textsc{Keywords:} Neural Network, COMPASS/AMBER, Chi-Squared}
}


% The actual document starts here
\begin{document}

\maketitle

\section{Introduction}

\subsection{COMPASS/AMBER}

The COMPASS experiment, short for "Common Muon and Proton Apparatus for Structure 
and Spectroscopy," is a cutting-edge particle physics experiment conducted at CERN, 
the European Organization for Nuclear Research, in Geneva, Switzerland. COMPASS is a 
collaborative endeavour involving scientists and researchers from institutions around the world.
This experiment is dedicated to unravelling the mysteries of the subatomic world by probing the 
structure and properties of hadrons, which are particles composed of fundamental constituents 
called quarks and held together by a strong nuclear force. COMPASS achieves this by utilizing 
a high-energy polarized muon beam, making it unique in its precision measurements of hadron 
physics and spin properties.
With its sophisticated array of detectors, including spectrometers and tracking chambers, 
COMPASS captures and analyzes particles produced during high-energy collisions, providing 
valuable insights into the internal structure of nucleons like protons and neutrons. 
Additionally, COMPASS explores the production of exotic hadrons, expanding our understanding 
of the strong force interactions and the fundamental constituents of matter.
The data generated by the COMPASS experiment contributes significantly to advancing our 
knowledge of the building blocks of the universe and the forces that govern them, 
furthering our understanding of the intricacies of particle physics.


\section{Data Origin and Preprocessing}

\subsection{Data Origin: Generation and Reconstruction}
The data used for the analysis presented in this paper was generated using a LEPTO generator,
a dedicated generator for deep inelastic scattering (DIS) processes. Beyond that, the full simulation
of the COMPASS spectrometer was done using the GEANT4 programme. The data was then reconstructed
using the COMPASS reconstruction software. With this process, two files were generated for each type of events (Hadrons and Inclusive), one with the
Monte Carlo (MC) data, and another with the reconstructed data. 
The goal with this data is to check if it is possible to predict the acceptance of the COMPASS/AMBER
using a Neural Network, since the GEANT4 simulation is very time consuming, aproximately 30 seconds per event.
That might not seem like a lot, but when you have millions of events, it becomes a problem.
Therefore, one could use a Neural Network to have a better idea of how changed parameters affect the data/MC
agreement, and then only run the GEANT4 simulation for the events that are more likely to be accepted.


\subsection{Data Variables}
In this study, we used two types of events, Inclusive and Hadrons. The Inclusive events are events where the muon is detected, while the Hadrons events are events where hadrons are detected.
The data used for the analysis of the Inclusive events has 11 variables:

\begin{table}[H]
    \centering
    \resizebox{0.45\textwidth}{!}{\begin{tabular}{c|l}
    \textbf{Variable} & \textbf{Description} \\ \hline
    $X_b$ & $Bjorken_x$ \\
    $Y$ & Virtual Photon Energy Fraction of the initial momentum\\
    $Q^2$ & Four-momentum transfer \\
    $Trig$ & Trigger \\
    $PV_z$ & X-Position of interaction vertex in the target\\
    $PV_x$ & Y-Position of interaction vertex in the target\\
    $PV_y$ & Z-Position of interaction vertex in the target\\
    $Mom_{mu}$ & Incoming beam momentum\\
    $Mom_{mup}$ & Outgoing muon momentum\\
    $d_xd_zmup$ & Angle of Muon \\
    $d_{y}d_{z}mup$ & Angle of Muon \\
    \end{tabular}
    }
\end{table}

While the data used for the analysis of the Hadrons events has 16 variables:

\begin{table}[H]
    \centering
    \resizebox{0.45\textwidth}{!}{\begin{tabular}{c|l}
    \textbf{Variable} & \textbf{Description} \\ \hline
    $X_b$ & $Bjorken_x$ \\
    $Y$ & Virtual Photon Energy Fraction of the initial momentum\\
    $Z$ & Fraction of hadron energy to the virtual photon energy \\
    $Q^2$ & Four-momentum transfer \\
    $Trig$ & Trigger \\
    $PV_z$ & X-Position of interaction vertex in the target\\
    $PV_x$ & Y-Position of interaction vertex in the target\\
    $PV_y$ & Z-Position of interaction vertex in the target\\
    $Mom_{mu}$ & Incoming beam momentum\\
    $Mom_{mup}$ & Outgoing muon momentum\\
    $d_xd_zmup$ & Angle of Muon \\
    $d_yd_zmup$ & Angle of Muon \\
    $q$ & Hadron Charge \\
    $mom$ & Momentum of Hadron \\
    $d_xd_z$ & Angle of Hadron \\
    $d_yd_z$ & Angle of Hadron \\
    \end{tabular}
    }
\end{table}



As mentioned before, for each type of events, we have a file with the Monte Carlo data and another with the reconstructed data.
Since the goal is to find a way to predict the acceptance of the COMPASS/AMBER, we created a new variable, called "Accepted",
which is 1 if the event was reconstructed and 0 if it was generated. Therefore, for the data with the Monte Carlo information, we added
a column with the value 0 for all the events, and for the data with the reconstructed information, we added a column with the value 1.
It's important to refer that the number of events for each of the files is different, since the Monte Carlo data has more events than the reconstructed data.
Hence, we had to balance the data for the training and testing of the Neural Network, which will be explained in the following sections.

\subsection{Data Visualization}
In order to have a better understanding of the data, we plotted the histograms for each of the variables, for the Inclusive and Hadrons events.

\textbf{Some histograms for the Inclusive events are shown in the figures below:}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/incl_X_b.png}
    \caption{Histogram for $X_b$}
    \label{fig:incl_X_b}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/incl_Y.png}
    \caption{Histogram for $Y$}
    \label{fig:incl_Y}
\end{figure}


% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/incl_Q2.png}
%     \caption{Histogram for $Q^2$}
%     \label{fig:incl_Q2}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.45\textwidth]{graphs/incl_Trigger.png}
%     \caption{Histogram for $Trigger$}
%     \label{fig:incl_Trig}
% \end{figure}



% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/incl_PV_z.png}
%     \caption{Histogram for $PV_z$}
%     \label{fig:incl_PV_z}
% \end{figure}

% \begin{figure}[H]
%     \centering\includegraphics[width=0.45\textwidth]{graphs/incl_PV_x.png}
%     \caption{Histogram for $PV_x$}
%     \label{fig:incl_PV_x}
% \end{figure}



% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/incl_PV_y.png}
%     \caption{Histogram for $PV_y$}
%     \label{fig:incl_PV_y}
% \end{figure}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.45\textwidth]{graphs/incl_Momentum_mu.png}
%     \caption{Histogram for $Mom_{mup}$}
%     \label{fig:incl_Momentum_mu}
% \end{figure}



% \begin{figure}[H]
% \centering
% \includegraphics[width=0.45\textwidth]{graphs/incl_Beam_Momentum.png}
%     \caption{Histogram for $Mom_{mu}$}
%     \label{fig:incl_Momentum_mup}
% \end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{graphs/incl_dx_dz_mu.png}
    \caption{Histogram for $d_xd_zmup$}
    \label{fig:incl_Angle_mu_1}
\end{figure}

\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/incl_dy_dz_mu.png}
    \caption{Histogram for $d_yd_zmup$}
    \label{fig:incl_Angle_mu}
\end{figure}


Since we're going to use a 2D histogram for the chi-squared test to further evaluate the performance of the models, we plotted the 2D histogram for the $X$ and $Y$ variables for the Inclusive:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/incl_xb_y_gen.png}
    \caption{2D Histogram with $X$ and $Y$ for the Inclusive Events: Generated}
    \label{fig:inclusive_2D_histogram_gen}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/incl_xb_y_rec.png}
    \caption{2D Histogram with $X$ and $Y$ for the Inclusive Events: Reconstructed}
    \label{fig:inclusive_2D_histogram_rec}
\end{figure}

\textbf{Some histograms for the Hadrons events are shown in the figures below:}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/hadr_X_b.png}
    \caption{Histogram for $X_b$}
    \label{fig:had_X_b}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/hadr_Y.png}
    \caption{Histogram for $Y$}
    \label{fig:had_Y}
\end{figure}


\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/hadr_Z.png}
    \caption{Histogram for $Z$}
    \label{fig:had_Z}
\end{figure}
% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_Q2.png}
%     \caption{Histogram for $Q^2$}
%     \label{fig:had_Q2}
% \end{figure}


% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_Trigger.png}
%     \caption{Histogram for $Trig$}
%     \label{fig:had_Trig}
% \end{figure}
% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_PV_z.png}
%     \caption{Histogram for $PV_z$}
%     \label{fig:had_PV_z}
% \end{figure}



% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_PV_x.png}
%     \caption{Histogram for $PV_x$}
%     \label{fig:had_PV_x}
% \end{figure}
% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_PV_y.png}
%     \caption{Histogram for $PV_y$}
%     \label{fig:had_PV_y}
% \end{figure}



% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_Momentum_mu.png}
%     \caption{Histogram for $Mom_{mup}$}
%     \label{fig:had_Momentum_mu}
% \end{figure}
% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_Beam_Momentum.png}
%     \caption{Histogram for $Mom_{mu}$}
%     \label{fig:had_Momentum_mup}
% \end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/hadr_Momentum.png}
    \caption{Histogram for $d_xd_zmup$}
    \label{fig:had_Angle_mu_2}
\end{figure}
% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_dy_dz_mu.png}
%     \caption{Histogram for $d_yd_z \mu p$}
%     \label{fig:had_Angle_u_3}
% \end{figure}


\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/hadr_dy_dz.png}
    \caption{Histogram for $d_yd_z$}
    \label{fig:had_Angle_m}
\end{figure}
\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/hadr_dx_dy.png}
    \caption{Histogram for $d_xd_z$}
    \label{fig:had_Angle}
\end{figure}



% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_dx_dy_mu.png}
%     \caption{Histogram for $d_xd_z \mu$}
%     \label{fig:had_Angle_mu}
% \end{figure}
% \begin{figure}[H]
% \centering
%     \includegraphics[width=0.45\textwidth]{graphs/hadr_Charge.png}
%     \caption{Histogram for Charge}
%     \label{fig:had_mom}
% \end{figure}


For the Hadrons events, we are going to use a 3D tensor for the $X$, $Y$ and $Z$ variables to further evaluate the performance of the models.
Since we cannot plot a histogram that allows us to visualize this '3D histogram', no image will be presented here, but it will be used in the chi-squared test.
One could plot several 2D histograms, one for each $Z$ value, but that would be very time-consuming and not very practical.


\subsection{Correlation between Variables}
In order to check if there is any correlation between the variables, we plotted the correlation matrix with the Pearson Coefficient for the Inclusive and Hadrons events.
This is important because if there is a high correlation between two variables, it means that they are redundant, and therefore, one of them can be removed, 
which simplifies the training of the Neural Network, reduces the number of parameters (reducing the training time) and avoids overfitting.
The results are shown in the figures below:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/inclusive_correlation_matrix.png}
    \caption{Correlation Matrix for the Inclusive Events}
    \label{fig:inclusive_correlation_matrix}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{graphs/hadron_correlation_matrix.png}
    \caption{Correlation Matrix for the Hadron Events}
    \label{fig:hadron_correlation_matrix}
\end{figure}


As seen in the figures above, there is a high correlation between $Y$ and $Mom_{mup}$, with
a Pearson correlation coefficient of -0.99 for both types of events. Therefore, one of them can be removed from the training
of the Neural Network. Since $Mom_{mup}$ and $Y$ have the same correlation coefficient, we decided to remove $Mom_{mup}$ from the training of the Neural Network,
since from the physics point of view, $Y$ is more important than $Mom_{mup}$, since it is the variable that gives us the virtual photon energy fraction of the initial momentum. 

\subsection{Weighting}
As previously mentioned, the datasets from the Monte Carlo and the reconstructed data exhibit variations in the number of events.
The Monte Carlo dataset contains a larger number of events compared to the reconstructed data. Consequently, we needed to address this disparity to ensure fair and effective training and testing of the Neural Network.

Our approach involved a two-step process. Initially, we trained the Neural Network using only a small percentage of the data to fine-tune the hyperparameters. Subsequently, we performed the main training using the entire dataset and tested the model with the full dataset. However, due to the differing event counts in each dataset, it was imperative to balance the data during both stages of training and testing.

While fine-tuning the hyperparameters, it was not feasible to utilize an equal count of events from the Reconstruction and Generation datasets, given their inherent numerical differences. Therefore, our solution involved using a proportional representation by employing percentages of the data. This approach is crucial because using an event count-based method would result in varying proportions of accepted and rejected events in the training and testing datasets, which could skew the model's performance evaluation.


\section{Neural Network Architecture and Training}

\subsection{Models Architecture}

For the Neural Networks models, we used the PyTorch framework, which is an open-source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing.
For the models architecture, two different models were used, one with 3 hidden layers, two GELU activation functions and two dropout layers, and another with 6 hidden layers, 5 GELU activation functions and 3 dropout layers.
The choice of the number of hidden layers and the number of neurons in each layer was done by trial and error, and the same applies to the choice of the dropout rate. 
The GELU activation function was chosen because it is the one that gave the best results, and the same applies to the choice of the optimizer, which was the Adam optimizer.
These two models were chosen because they are the ones that gave the best results and also because there was a need to see the difference between a not-so-deep model and a deeper model.
The hyperparameters used for the training of the models were the following:
\begin{itemize}
    \item Learning Rate: 0.01
    \item Epochs: 10
    \item Batch Size: Sample Size
\end{itemize}

For the loss function, we used the Binary Cross Entropy Loss, which is the most common loss function used for binary classification problems.
Despite the fact that this set of data might be familiar with a binary classification problem, since we are trying to predict if an event will be accepted or rejected,
we are not doing a binary classification problem, since we are not trying to classify the events, but rather predict the acceptance of the COMPASS/AMBER.
Therefore, there was no need to round the output of the Neural Network to 0 or 1. 

It is crucial to emphasize that the network is designed to predict $\frac{R}{R+G}$, and given that $R$ is a subset of $G$,
the results naturally fall within the range of 0 to 0.5. This nuance underscores the rationale behind avoiding the binary
rounding of Neural Network outputs.

Derived from the network's objective of predicting $\frac{R}{R+G}$, we determined that adjusting the acceptance probability
is necessary. A suitable adjustment is given by $\frac{1 - \text{NN}_{\text{out}}}{\text{NN}_{\text{out}}}$, ensuring the
scaled output lies within the range of 0 to 0.5.

During the adjustment process, we initially considered applying it on an event-by-event basis. However, this approach
resulted in an unexpectedly high chi-squared value, indicative of divergence from the expected value. Consequently,
we adopted an alternative strategy, deciding to implement the adjustment at the final mean value for a given bin within
the proposed histograms. This adjustment method yielded a chi-squared value closer to the anticipated value.



% Beyond that, it's important to refer that  
% the network aims at $\frac{R}{R+G}$ and since $R$ is a subsample of $G$, results will be between 0 and 0.5, which is also
% the reason one should not round the output of the Neural Network to 0 or 1.

% From the fact that the network aims at $\frac{R}{R+G}$, we concluded that the Acceptance of the Neural Network
% should be adjusted to $\frac{1 - NN_{out}}{NN_out}$ in order to scale it from the range 0 to 0.5. 
% While doing this we discovered that doing it event by event would result in a very high chi-squared value,
% indicating that this value was diverging from the expected value. Therefore, we decided to do it in a different way.
% We, then, concluded that by doing it in the final mean value for a a given bin in the proposed histograms,
% the chi-squared value would be closer to the expected value. 




\subsection{Evaluation of the Models}

During the training of the models, we kept the chi-squared as a metric to evaluate the performance of the models.
The chi-squared test is a statistical hypothesis test that is used to evaluate how well a set of data fits a model.
In this case, the model is the Neural Network, and the data is the data used for the training and testing of the Neural Network.
For this particular case, the chi-squared was applied to:
\begin{itemize}
    \item Hadrons: 3D histogram with $X$, $Y$ and $Z$ variables
    \item Inclusive: 2D histogram with $X$ and $Y$ variables
\end{itemize}

The chi-squared used was defined as:

\begin{equation}
    \chi^2 = \sum_{i=1}^{N} \frac{(\frac{r}{g} - A_{nn})^2}{err^2}
\end{equation}
    
where $r$ is the number of reconstructed events in the bin, $g$ is the number of generated events in the bin, $A_{nn}$ is the output of the Neural Network for the bin and $err$ is the error of the bin, which is defined as:

\begin{equation}
    err^2 = \frac{rg + r^2}{g^3}
\end{equation}

For Inclusive events, we anticipate a chi-squared value of approximately 45. It's worth noting that the expected value should theoretically be 60 since there are 60 bins. However, due to certain bins appearing to be empty, we are expecting a somewhat lower value.

In the case of Hadron events, we are looking for a chi-squared value of roughly 400. Similarly, the theoretical expected value would be 780, corresponding to the number of bins. Nonetheless, given the presence of apparently empty bins, we anticipate a reduced value.

\subsection{Training, Testing and Results}

During the model training process, an 80\% portion of the dataset was dedicated to training, while the remaining 20\% was allocated for testing. Notably, both models underwent training and testing with the same dataset to ensure a fair basis for comparison.

Throughout the training phase, the primary focus was on tracking the chi-squared values, which played a crucial role in identifying the best models.

It's worth noting that the chi-squared values exhibited some instability during training. To account for this, models with chi-squared values were preserved for post-training model selection. This approach allowed for the selection of the best models after considering the chi-squared performance.

Multiple iterations of training were carried out due to the previously mentioned chi-squared instability. To gain insights
into the training process, the chi-squared was plotted and visualized, as depicted
in the figure below:

For the Hadron events: 
\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/nn_hadrons_metrics.png}
    \caption{Shallow Model for Hadron}
    \label{fig:accuracy_loss_hadr}
\end{figure}
\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/nn_hadrons_metrics_deeper.png}
    \caption{Deep Model for Hadron}
    \label{fig:accuracy_loss_hadr_deep}
\end{figure}


For the Inclusive events:

\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/nn_incl_metrics.png}
    \caption{Shallow Model for Inclusive}
    \label{fig:accuracy_loss_incl}
\end{figure}
\hfill
\begin{figure}[H]
\centering
    \includegraphics[width=0.45\textwidth]{graphs/nn_incl_metrics_deeper.png}
    \caption{Deep Model for Inclusive}
    \label{fig:accuracy_loss_incl_deep}
\end{figure}




Please keep in mind that the image presented here represents just a few of the training sessions.

As observed in the images above, the deeper model exhibited a relatively stable performance but yielded notably high
chi-squared values. On the other hand, the less deep model displayed instability but delivered lower chi-squared values.
Consequently, we made the decision to discontinue the deeper model and retain the less deep one, even though it exhibited
some instability. This decision was made based on the chi-squared values, which are the key evaluation criteria.
Due to this choice, we needed to be careful when selecting the best models, since the chi-squared values were not stable
and, thus, we needed to select models that were, on average, the ones in the middle of the training process, not the ones
in the end. 

Following multiple training sessions and employing a transfer learning approach—initiating the training process with the weights from the best-performing model among the previous runs—we successfully obtained models that met the required chi-squared criteria.

To assess the performance of the models, we computed the mean value of the ratio of counts per bin, comparing the observed data with the output generated by the Neural Network.
The results are presented in the table below:

\begin{table}[H]
    \centering
    \begin{tabular}{c|c}
    \textbf{Inclusive} & \textbf{Hadron} \\ \hline
    1.01702 & 1.08094 \\
    \end{tabular}
\end{table}


As evident from the above means, the model is making accurate predictions regarding the acceptance of COMPASS/AMBER.


\subsection{Genelarization with Other Data}
In order to assess the models' generalization capabilities, we employed a separate dataset and generated histograms for the Neural Network's output concerning both Inclusive and Hadron events.
We then proceeded to divide the output by the True Acceptance and calculated the mean value of the ratio, which is presented in the table below:

\begin{table}[H]
    \centering
    \begin{tabular}{c|c}
    \textbf{Inclusive} & \textbf{Hadron} \\ \hline
    1.00948 & 1.07528 \\ 
    \end{tabular}
\end{table}

As the ratio is close to 1, the models predict the acceptance of the COMPASS/AMBER as desired.

\section{Structure of the Spectometer}
Out of curiosity, we contemplated the possibility of utilizing the muon and hadron angles to reconstruct the detector's structure. It is well understood that when particles interact with physical objects, they may either be absorbed or deflected, leading to a loss in acceptance. As a result, we proceeded to generate histograms for the angles of the muon and the hadron, the effects of which can be observed in the figures below:


    \begin{figure}[H]
        \includegraphics[width=0.45\textwidth]{graphs/incl_angle.png}
        \caption{Structure Reconstruction with Muon Angle}
        \label{fig:muon_angle}
    \end{figure}
    
    \begin{figure}[H]
        \includegraphics[width=0.45\textwidth]{graphs/hadron_angle.png}
        \caption{Structure Reconstruction with Hadron Angle}
        \label{fig:hadron_angle}
    \end{figure}


In figure \ref{fig:muon_angle} we can see kind of a hole in the middle of the histogram, this comes from the fact
that we have $Q^2 > 1$ and we need finite angles for $\mu'$, thus it was expected that the $g$ inner region
should be empty, as shown in the figure referenced before. However, on the left edge we can see a band
between 0.0 and 0.25 (more or less), which can indicate an inefficiency slab in the spectrometer for muons.

In the figure \ref{fig:hadron_angle} we can see a structure and a rectangular frame. To confirm if indeed it's
the structure of the spectrometer, one needs to have the real structure of the spectrometer and compare it with the histogram.
Unfortunately, we don't have the real structure of the spectrometer, so we cannot confirm if the histogram is indeed the structure of the spectrometer.


\section{Improvements}
This problem is inherently challenging due to the complex nature of the data and the substantial volume of events involved.
As such, there is considerable potential for enhancement. One avenue for improvement involves exploring alternative Neural
Network architectures, such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Graph Neural Networks (GNN),
among others. It's worth noting that these architectures were not employed in this project due to constraints related to time,
computational resources, and project scope.

Another possible improvement involves the use of a different loss function. The best approach would be to use Chi-Squared
as a loss function, but that was not possible to implement during this project due to the lack of time and scope of the project.



\section{Conclusion}
In this study, we focused on predicting the acceptance of COMPASS/AMBER using Neural Networks. The COMPASS experiment at CERN,
dedicated to exploring the subatomic world, provided extensive data generated by a LEPTO generator and simulated using GEANT4.
The goal was to address the time-consuming nature of GEANT4 simulations by developing Neural Network models capable of predicting
particle acceptance.

Two distinct Neural Network architectures were employed, differing in depth and activation functions. The training process involved
evaluating model performance based on chi-squared tests, with a focus on achieving stable results. Despite some instability in the
training process, models were selected post-training, considering their overall performance.

The data, comprising Inclusive and Hadron events, underwent preprocessing, including balancing and visualization. Correlation
matrices aided in identifying redundant variables, streamlining the training process.

Weighting was implemented to handle variations in event counts between Monte Carlo and reconstructed datasets. The Neural
Network's objective was to predict $\frac{R}{R+G}$, requiring an adjustment to $\frac{1 - \text{NN}{\text{out}}}{\text{NN}{\text{out}}}$.
Adjustments were performed at the final mean value for bins in proposed histograms, resulting in improved chi-squared values.

During the training process, both shallow and deep models were considered, with a preference for models achieving lower
chi-squared values. Transfer learning further improved model performance.

The evaluation of the models revealed mean ratios close to 1 for both Inclusive and Hadron events, indicating accurate
predictions of COMPASS/AMBER acceptance. Additionally, the models demonstrated generalization capabilities when tested with
a separate dataset.

Exploring the potential reconstruction of the spectrometer's structure using muon and hadron angles was also considered.
Histograms of these angles were generated, laying the groundwork for future investigations into understanding the impact of
particle interactions with physical objects on detector acceptance.

In conclusion, the Neural Network models presented promise in predicting COMPASS/AMBER acceptance, offering a more efficient
alternative to time-consuming GEANT4 simulations. Future work could explore alternative neural network architectures to further
enhance predictive capabilities and delve deeper into the intricacies of spectrometer reconstruction.




\bibliography{BibTexFile}
%
% Non-BibTeX users please use


\end{document}

% end of file template.tex

